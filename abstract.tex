This dissertation is about computational tools based on randomized numerical
linear algebra for handling large-scale matrix data. Since large datasets became
commonly available in a wide variety of modern applications, there has been an
increasing demand of numerical methods for storing, processing, and learning
from them. Matrices, the classical form for representing datasets, naturally
connect these tasks with the rich literature of numerical linear algebra. In the
past few decades, scalability has emerged as a central theme of the field, as
the growth of data starts to surpass the development in computational power. For
a diverse collection of problems, randomized methods offer extraordinary
efficiency and flexibility by introducing controlled stochasticity according to
classical perturbation theory. This work focuses on using randomized
numerical linear algebra to build practical algorithms for problems of massive
size and high complexity that traditional methods are unable to handle
otherwise. Through this dissertation, we explore topics across network science,
Gaussian processes regression, natural language processing, and quantum
chemistry. Our contribution includes a collection of scalable and robust
numerical methods under a unifying theme, accompanied by efficient
implementations. As a result, we are able to significantly speed up the
computation for some current applications, and explore problems and datasets
that were intractable before.
