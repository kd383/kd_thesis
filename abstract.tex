This dissertation is about computational tools based on randomized numerical
linear algebra for handling large\hyp{}scale matrix data. Since large datasets
have become commonly available in a wide variety of modern applications, there
has been an increasing demand for numerical methods for storing, processing, and
learning from them. Matrices, the classical form for representing datasets,
naturally connect these tasks with the rich literature of numerical linear
algebra. For a diverse collection of problems, randomized methods offer
extraordinary efficiency and flexibility. This work focuses on using randomized
numerical linear algebra to build practical algorithms for problems of massive
size and high complexity that traditional methods are unable to handle. Through
this dissertation, we explore topics across network science, Gaussian process
regression, natural language processing, and quantum chemistry. Our contribution
includes a collection of scalable and robust numerical methods under a unifying
theme, accompanied by efficient implementations. As a result, we are able to
significantly speed up the computation for several existing applications, and
explore problems and datasets that were intractable before.